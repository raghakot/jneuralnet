/*
 * Copyright (c) 2008-2009 Kotikalapudi Raghavendra. All Rights Reserved.
 *
 * Licensed under the Creative Commons License Attribution-NonCommercial-ShareAlike 3.0,
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at http://creativecommons.org/
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package jneuralnet.core.activation;

import jneuralnet.core.Pluggable;

/**
 * This abstract class defines the activation function that can be used with
 * a {@code Neuron}. Newer activation functions can be defined by
 * extending this class.
 *
 * <p>The choice of activation function determines the range of
 * output values generated by a <code>Neuron</code>.
 *
 * <p> This class extends the <tt>Pluggable</tt> class making it
 * self descriptive in nature.
 *
 * @author Ragha
 * @see Pluggable
 * @see Sigmoid 
 * @see LogisticSigmoid
 * @version 1.0
 */
public abstract class AbstractActivation extends Pluggable
{
    /**
     * Defines the threshold function otherwise known as 
     * <tt>Activation Function</tt>.
     *
     * @param input The input 'x' to activation function F(x)
     * @return the activation value computed using the input
     */
    public abstract Double activation(Double input);
    
    /**
     * This functions defines the derivative of the activation function.
     *
     * @param input
     * @return The derviative(activation(input)), ie, F`(input)
     */
    public abstract Double activationDerviative(Double input);
}
