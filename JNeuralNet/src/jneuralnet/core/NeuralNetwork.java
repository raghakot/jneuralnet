/*
 * Copyright (c) 2008-2009 Kotikalapudi Raghavendra. All Rights Reserved.
 *
 * Licensed under the Creative Commons License Attribution-NonCommercial-ShareAlike 3.0,
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at http://creativecommons.org/
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package jneuralnet.core;

import jneuralnet.core.training.Teacher;
import com.thoughtworks.xstream.XStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.io.PrintWriter;
import java.io.Serializable;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Scanner;
import jneuralnet.core.learning.AbstractLearningAlgo;
import jneuralnet.core.learning.costfunction.AbstractCostFunction;
import jneuralnet.core.preprocessor.AbstractInputPreprocessor;
import jneuralnet.core.preprocessor.AbstractOutputPreprocessor;
import jneuralnet.core.training.TrainingDataRepository;
import jneuralnet.core.training.TrainingPattern;
import jneuralnet.core.training.TrainingSet;

/**
 * A <code>NeuralNetwork</code> represents an Input Layer, Output Layer
 * with optional Hidden Layers between them. It consists of <code>NeuronLayer</code>
 * objects connected together by <code>SyanpticConnection</code> objects.
 *
 * <p>This class forms the basis to any NeuralNetwork based application. When
 * assigned to a <code>Teacher</code> it can discover input ,
 * output mapping defined by the <code>TrainingSet</code>.
 *
 * <p>The predicted output of the network is generated by
 * {@link NeuralNetwork#getOutput(java.lang.Double[]) getOutput(..)} or
 * {@link NeuralNetwork#getOutputOnPreprocessedData(java.lang.Double[])  getOutputOnPreprocessedData(..)}
 * methods.
 *
 * <p>This class extends the <tt>Bufferable</tt> and hence supports
 * dynamic property addition.
 *
 * @author Ragha
 * @see Teacher
 * @see TrainingSet
 * @see NeuronLayer
 * @version 1.1
 */
public class NeuralNetwork extends Bufferable implements Serializable
{
    private static final long serialVersionUID = -7157977445206331948L;

    /**
     * ArrayList of <code>NeuronLayer</code> objects for all the hidden
     * layers in the network.
     *
     * @see NeuronLayer
     */
    private ArrayList<NeuronLayer> arrHiddenLayers 
            = new ArrayList<NeuronLayer>();

    /**
     * Output layer of the network
     * @see NeuronLayer
     */
    private NeuronLayer outputLayer = new NeuronLayer(1);

    /**
     * Number of inputs to this neural network. This also represents
     * the Input Layer to the network.
     */
    private Integer numInputs;
       
    /**
     * The teacher object for this network...
     */
    private Teacher teacher;

    /**
     * 
     * @return The teahcer associated with this neural network...
     */
    public Teacher getTeacher()
    {
        return teacher;
    }
       
    /**
     * Creates a neural network with an output layer with
     * neurons equivalent to the number of outputs of the network.
     * 
     * <p>Each neuron in the output layer has synaptic connections
     * equivalent to the number of inputs of the network.
     *     
     * @param inputs The desired number of inputs to the network.
     * @param outputs The desired number of outputs to the network.
     * @throws java.lang.IllegalArgumentException If number of inputs
     * or outputs is less than 1.
     */
    public NeuralNetwork(Integer inputs,Integer outputs) 
            throws IllegalArgumentException
    {
        setNumInputs(inputs);
        setNumOutputs(outputs);
        refreshConnections();
        teacher = new Teacher(this);
    }

    /**
     * Sets the number of inputs to a neurtal network
     * @param numInputs The number of neurons to be used in the input layer.
     * @throws java.lang.IllegalArgumentException If num of inputs is
     * less than 1
     */
    public void setNumInputs(int numInputs) throws IllegalArgumentException
    {
        if(numInputs < 1)
        {
            throw new IllegalArgumentException("Neural network cannot have " +
                    numInputs + " inputs");
        }
        else
            set("numInputs", numInputs);
    }

    /**
     * Sets the num of outputs for this network.
     * @param numOutputs The num of output layer neurons to be used
     * @throws java.lang.IllegalArgumentException If the num outputs is
     * less than 1
     */
    public void setNumOutputs(int numOutputs) throws IllegalArgumentException
    {
        outputLayer.setNumNeurons(numOutputs);        
    }
    
    /**
     * Adds a new Hidden layer to the network and refreshes the connections.
     * <p>
     * <b>NOTE: By refreshing the connections, all synaptic connections
     * in the network are randomized</b>
     * 
     * @param layer The <code>NeuronLayer</code> to be added to the network.
     * @see #refreshConnections()
     */
    public void addLayer(NeuronLayer layer)
    {        
        arrHiddenLayers.add(layer);  
        refreshConnections();
    }
    
    /**
     * Removes a hidden layer from the network.
     * @param index The index of the hidden layer to be removed.
     * The method simply returns if the index is invalid.
     */
    public void removeLayer(int index)
    {
        if(index < arrHiddenLayers.size())
        {
            arrHiddenLayers.remove(index);                                
            refreshConnections();
        }
    }
        
    /**
     * Estabilishes missing connections between all the neurons in the network.
     * <p>
     * <b>NOTE: By refreshing the connections, all synaptic connections
     * in the network are randomized</b>
     * <p>
     * <b>TODO: prune synaptic connections or add it where ever necessary.</b>
     */
    public void refreshConnections()
    {
        NeuronLayer prevLayer,curLayer;     
        int layerIndex = 0;
        int totLayers = 1 + arrHiddenLayers.size();
             
        while(layerIndex < totLayers)        
        {
            if(layerIndex == 0)
                prevLayer = null;
            else
                prevLayer = arrHiddenLayers.get(layerIndex - 1);
            
            try
            {
                curLayer = arrHiddenLayers.get(layerIndex);                    
            }
            catch(IndexOutOfBoundsException ex)
            {
                curLayer = outputLayer;
            }                        
            
            if(prevLayer == null)
            {
                for(Neuron n : curLayer.getNeurons())
                {
                    n.getInputConnections().clear();
                    n.getOutputConnections().clear();
                    
                    for(int i=0;i<numInputs;i++)
                        n.addInputConnection(new SynapticConnection());                                
                }
            }                
            else
            {
                prevLayer.flushOutputConn();
                curLayer.flushInputConn();                
                prevLayer.connectTo(curLayer);
            }
            
            layerIndex++;            
        }
    } 
    
    /**
     * This function is the true crux of a neural network.
     * It gives a neural network's prediction to any unknown
     * input vector.
     *
     * <p> This function uses input processor and
     * output de-processor used prior to training.
     *
     * <p> A Network is typically trained with a <tt>LearningAlgo</tt> before
     * using this method.
     *
     * @param input The input vector presented to the network.
     * @throws IllegalArgumentException If input length dosent match the num
     * of inputs of the neural network...
     * 
     * @see AbstractLearningAlgo
     * @see #setInputPreprocessor(jneuralnet.core.preprocessor.AbstractInputPreprocessor) setInputPreprocessor(...)}
     * @see #setOutputPreprocessor(jneuralnet.core.preprocessor.AbstractOutputPreprocessor) setOutputPreprocessor(...)}
     */
    public Double[] getOutput(Double input[]) throws IllegalArgumentException
    {
        if(input.length != numInputs) {
            throw new IllegalArgumentException("Input data length "
                    + "does not match num of inputs to the neural network");
        }

        if(inputPreprocessor != null)
            input = inputPreprocessor.process(input);

        Double output[] = input;
        
        //feed forwarding the data through hidden layers...
        for(NeuronLayer hiddenLayer : arrHiddenLayers)
            output = hiddenLayer.getOutput(output);
        //feed forwarding the data through output layer...
        output = outputLayer.getOutput(output);

        if(outputPreprocessor != null)
            output = outputPreprocessor.deProcess(output);

        return output;
    }

    /**
     * Use this method when data is preprocessed. ie, typically in the
     * LearningAlgo for feed forwarding the data...
     *
     * <p> This method differs from {@link #getOutput(java.lang.Double[]) getOutput(...)} \
     * method by not using the input preprocessor and output de-processor to
     * generate output.
     *
     * <p> A Network is first trained with a <tt>LearningAlgo</tt> before
     * using this method.
     *
     * <p> It also updates all the cached values of a <code>Neuron</code>.
     * The cached values find their use in implementing <tt>LearningAlgo</tt>
     * interface. The cached values are used by learning algo.
     *
     * @param input The input vector presented to the network.
     * @see AbstractLearningAlgo
     */
    public Double[] getOutputOnPreprocessedData(Double input[])
    {
        Double output[] = new Double[input.length];
        System.arraycopy(input, 0, output, 0, input.length);

        //feed forwarding the data through hidden layers...
        for(NeuronLayer hiddenLayer : arrHiddenLayers)
            output = hiddenLayer.getOutput(output);
        //feed forwarding the data through output layer...
        output = outputLayer.getOutput(output);

        return output;
    }
    
    /**     
     * @return The number of input's to this neural network.
     */       
    public Integer getNumInputs()
    {
        return numInputs;
    }
    
    /**     
     * @return The number of output's to this neural network.
     */
    public Integer getNumOutputs()
    {
        return outputLayer.getNeurons().size();
    }
    
    /**
     * @return The number of hidden layers used in this network.
     */
    public Integer getNumHiddenLayers()
    {
        return arrHiddenLayers.size();
    }
    
    /**      
     * Gives the number of hidden layer neurons represented by the 'index'
     * value of the hidden layer.
     *
     * @param index The index value of the hidden layer.
     * @return The number of hidden layer neurons.
     *
     * @throws IndexOutOfBoundsException If index value is invalid.
     */
    public Integer getHiddenLayerNeurons(int index) 
            throws IndexOutOfBoundsException
    {
        return arrHiddenLayers.get(index).getNeurons().size();        
    }
    
    /**
     * Saves this neural network into a file.
     * This class is saved in serialized form.
     *
     * @param fname The name of the file to be saved as.
     * @throws IOException On some I/O error.
     */    
    @SuppressWarnings("empty-statement")
    public void saveNet(String fname) throws IOException
    {        
        if(teacher.isTraining())
        {
            teacher.pauseTraining();
            while(teacher.isPaused());     
        }

        FileOutputStream fout = null;
        ObjectOutputStream objOut = null;
        try
        {
            fout = new FileOutputStream(fname);
            objOut = new ObjectOutputStream(fout);
            objOut.writeObject(this);
        }
        catch(IOException e)
        {
            throw e;
        }
        finally
        {
            objOut.close();
            fout.close();

            //ignores any way's if not paused in the first place
            teacher.resumeTraining();
        }
    }
    
    /**
     * Loads a previously saved network from a file.
     *
     * @param fname The file path of the serialized neural network.
     * @return The NeuralNetwork loaded from the file.
     *
     * @throws IOException If some disk I/O error occurs or if the
     * serialized file is corrupt.
     */
    public static NeuralNetwork loadNet(String fname) throws IOException
    {
        FileInputStream fin = null;
        ObjectInputStream objIn = null;

        NeuralNetwork net = null;
        try
        {
            fin = new FileInputStream(fname);
            objIn = new ObjectInputStream(fin);
            net = (NeuralNetwork) objIn.readObject();
        }
        catch(ClassNotFoundException e)
        {
            throw new IOException("Neural Network file is corrupt");
        }
        catch(IOException e)
        {
            throw e;
        }
        finally
        {
            objIn.close();
            fin.close();
        }

        return net;        
    }

    /**
     * Saves the neural network in XML format
     * @param fname The file name to be used in saving the network.
     * @throws java.io.IOException On some I/O Error.
     */
    @SuppressWarnings("empty-statement")
    public void saveToXML(String fname) throws IOException
    {
        if(teacher.isTraining())
        {
            teacher.pauseTraining();
            while(teacher.isPaused());
        }

        PrintWriter pw = null;
        try
        {
            XStream xs = new XStream();
            String xml = xs.toXML(this);
            pw = new PrintWriter(fname);
            pw.print(xml);
        }
        catch(IOException e)
        {
            throw e;
        }
        finally
        {
            if(pw != null)
                pw.close();
            //ignores any way's if not paused in the first place
            teacher.resumeTraining();
        }
    }

    /**
     * Loads a neural network from an XML file.
     * @param fname The file name to be loaded from.
     * @return The NeuralNetwork represented by the XML file.
     * @throws java.io.IOException On Some I/O Exception.
     */
    public static NeuralNetwork loadFromXML(String fname) throws IOException
    {
        Scanner sc = null;
        try
        {
            String xml = "";
            sc = new Scanner(new File(fname));
            while(sc.hasNext())
                xml += sc.nextLine();

            XStream xs = new XStream();
            return (NeuralNetwork)xs.fromXML(xml);
        }
        catch(IOException e)
        {
            throw e;
        }
        finally
        {
            sc.close();
        }

    }

    /**
     * Evaluates the performance of the neural network on the
     * given training set. The error values are determined by using 
     * the cost function that is setup in the learning algo.
     *
     * <p> To set the learning algo use:
     * <i> <code>getTeacher().setLearningAlgo(...)</code> method</i>.
     *
     * <p> Cost function to as learning algo is setup using
     * <i> <code>learningAlgo.setCostFunction(...)</code> method</i>.
     *
     * @param ts The training set on which the performance is to
     * be evaluated.
     * @param isDataPreprocessed If set to false, the training data
     * is first preprocessed with input and output preprocessors, if any.
     * @return A HashMap with training pattern and its error as key and
     * value pairs.
     * @throws IllegalStateException If learning algo is not set prior to the call.
     *
     * @see #setInputPreprocessor(jneuralnet.core.preprocessor.AbstractInputPreprocessor) setInputPreprocessor(...)
     * @see #setOutputPreprocessor(jneuralnet.core.preprocessor.AbstractOutputPreprocessor) setOutputPreprocessor(...)
     * @see AbstractLearningAlgo
     * @see AbstractCostFunction
     */
    public HashMap<TrainingPattern, Double> getPerformanceOnTrainingSet(
            TrainingSet ts, boolean isDataPreprocessed) throws IllegalStateException
    {
        AbstractLearningAlgo algo = teacher.getLearningAlgo();
        if(algo == null)
            throw new IllegalStateException("Learning algo is not set up...");
        
        HashMap<TrainingPattern, Double> map = new HashMap<TrainingPattern, Double>();
        Double actual[];
        for(TrainingPattern tp : ts.getTrainingPatterns())
        {
            if(isDataPreprocessed)
                actual = getOutputOnPreprocessedData(tp.getInputData());
            else
                actual = getOutput(tp.getInputData());            
            map.put(tp, algo.getCostFunction().getErrorValue(tp.getOutputData(), actual));
        }
        return map;
    }

    /**
     * Uses the teacher's training data repository to evaluate performance on
     * the training data.
     *
     * @throws IllegalStateException If learning algo is not set prior to the call.
     * @return The map containing training patterns and their error values...
     * @see Teacher
     * @see TrainingDataRepository
     */
    public HashMap<TrainingPattern, Double> getPerformanceOnTrainingData()
            throws IllegalStateException
    {
        return getPerformanceOnTrainingSet(teacher.getTrainingDataRepository()
                .getProcessedTrainingSet(), true);
    }

    /**
     * Uses the teacher's training data repository to evaluate performance on
     * the validation data.
     *
     * @throws IllegalStateException If learning algo is not set prior to the call.
     * @return The map containing training patterns and their error values...
     * @see Teacher
     * @see TrainingDataRepository
     */
    public HashMap<TrainingPattern, Double> getPerformanceOnValidationData()
            throws IllegalStateException
    {
        return getPerformanceOnTrainingSet(teacher.getTrainingDataRepository()
                .getProcessedValidationSet(), true);
    }

    /**
     * Uses the teacher's training data repository to evaluate performance on
     * the test data.
     *
     * @throws IllegalStateException If learning algo is not set prior to the call.
     * @return The map containing training patterns and their error values...
     * @see Teacher
     * @see TrainingDataRepository
     */
    public HashMap<TrainingPattern, Double> getPerformanceOnTestData()
            throws IllegalStateException
    {
        return getPerformanceOnTrainingSet(teacher.getTrainingDataRepository()
                .getProcessedTestSet(), true);
    }

    /**     
     * @return The output layer used by this network
     */
    public NeuronLayer getOutputLayer()
    {
        return outputLayer;
    }
    
    /**
     * @return The list of hidden layer's used by this network
     */
    public ArrayList<NeuronLayer> getHiddenLayers()
    {
        return arrHiddenLayers;
    }

    /**
     * Represents the input preprocessor used by this neural network.
     * @see AbstractInputPreprocessor
     */
    private AbstractInputPreprocessor inputPreprocessor;

    /**
     *
     * @return The input preprocessor associated with this network.
     * A null value suggests that no preprocessor was used.
     */
    public AbstractInputPreprocessor getInputPreprocessor() {
        return inputPreprocessor;
    }

    /**
     * Sets the input preprocessor to be used with this network.
     * <tt>null</tt> value is permissible and its use
     * suggests that no preprocessor be used.
     *
     * <b> NOTE: Use the same preprocessor as used during the training.
     * Changing the preprocessor after training may have undesirable
     * side effects. </b>
     *
     * @param inputPreprocessor The input preprocessor to be used.
     * @see AbstractInputPreprocessor
     */
    public void setInputPreprocessor(AbstractInputPreprocessor inputPreprocessor) {
        set("inputPreprocessor", inputPreprocessor);        
    }

    /**
     * Represents the output preprocessor used by this neural network.
     * @see AbstractOutputPreprocessor
     */
    private AbstractOutputPreprocessor outputPreprocessor;

    /**
     *
     * @return The output preprocessor associated with this network.
     * A null value suggests that no preprocessor was used.
     */
    public AbstractOutputPreprocessor getOutputPreprocessor() {
        return outputPreprocessor;
    }

    /**
     * Sets the output preprocessor to be used with this network.
     * <tt>null</tt> value is permissible and its use
     * suggests that no preprocessor be used.
     * 
     * <b> NOTE: Use the same preprocessor as used during the training.
     * Changing the preprocessor after training may have undesirable
     * side effects. </b>
     * 
     * @param outputPreprocessor The output preprocessor to be used.
     * @see AbstractOutputPreprocessor
     */
    public void setOutputPreprocessor(AbstractOutputPreprocessor outputPreprocessor) {
        set("outputPreprocessor", outputPreprocessor);
    }    
    
    @Override
    public String toString()
    {        
        String s = "---NeuralNetwork Stats---\n";
        s += "numInputs = "+numInputs+"\n";
        s += "numOutputs = "+outputLayer.getNeurons().size()+"\n";
        
        s += "---OutputLayer Stats---\n";
        s += outputLayer.toString();
        s += "-----------------------\n";
        
        s += "---HiddenLayer Stats---\n";
        for(NeuronLayer l : arrHiddenLayers)
            s += l.toString();
        s += "-----------------------\n";
        
        return s;        
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        final NeuralNetwork other = (NeuralNetwork) obj;
        if (this.arrHiddenLayers != other.arrHiddenLayers && (this.arrHiddenLayers == null || !this.arrHiddenLayers.equals(other.arrHiddenLayers))) {
            return false;
        }
        if (this.outputLayer != other.outputLayer && (this.outputLayer == null || !this.outputLayer.equals(other.outputLayer))) {
            return false;
        }
        if (this.numInputs != other.numInputs && (this.numInputs == null || !this.numInputs.equals(other.numInputs))) {
            return false;
        }
        if (this.teacher != other.teacher && (this.teacher == null || !this.teacher.equals(other.teacher))) {
            return false;
        }
        if (this.inputPreprocessor != other.inputPreprocessor && (this.inputPreprocessor == null || !this.inputPreprocessor.equals(other.inputPreprocessor))) {
            return false;
        }
        if (this.outputPreprocessor != other.outputPreprocessor && (this.outputPreprocessor == null || !this.outputPreprocessor.equals(other.outputPreprocessor))) {
            return false;
        }
        return true;
    }

    @Override
    public int hashCode() {
        int hash = 7;
        hash = 37 * hash + (this.arrHiddenLayers != null ? this.arrHiddenLayers.hashCode() : 0);
        hash = 37 * hash + (this.outputLayer != null ? this.outputLayer.hashCode() : 0);
        hash = 37 * hash + (this.numInputs != null ? this.numInputs.hashCode() : 0);
        hash = 37 * hash + (this.teacher != null ? this.teacher.hashCode() : 0);
        hash = 37 * hash + (this.inputPreprocessor != null ? this.inputPreprocessor.hashCode() : 0);
        hash = 37 * hash + (this.outputPreprocessor != null ? this.outputPreprocessor.hashCode() : 0);
        return hash;
    }
}
